# Реализация GOAP + Utility в Almost Alive

Этот документ подробно описывает гибридную систему планирования поведения агентов (колонистов и животных), используемую в игре. Система сочетает в себе гибкость **Utility AI** для выбора целей и мощь **GOAP** для построения цепочек действий.

---

## 1. Архитектура: Utility + GOAP

Вместо классического GOAP, где цели фиксированы или выбираются простым приоритетом, мы используем **Utility-слой** для динамического определения наиболее важной цели в текущий момент.

### Как это работает:
1. **Utility AI (Goal Selection)**: Каждый кадр (или реже) мозг агента оценивает все доступные `GoalSO`. Каждый `GoalSO` имеет набор `GoalUtility` эвалюаторов.
2. **GOAP (Action Planning)**: Для цели с наивысшим Utility-баллом запускается `GOAPPlanner`, который строит план действий методом обратного связывания (backward chaining).
3. **Execution**: Агент выполняет действия из плана. Если мир изменился и действие стало невозможным, план пересчитывается.

---

## 2. Слой Utility: Выбор Цели

Utility-балл цели рассчитывается в `GoalTemplate.EvaluateUtility` путем перемножения базового веса (`utilityBias`) на значения всех связанных эвалюаторов.

**Пример из игры: Цель "Утолить голод"**
- **utilityBias**: 1.0
- **StatRangeUtilityEvaluator**: Возвращает 0.0, если голод > 80, и экспоненциально растет до 1.0 по мере приближения голода к 0.
- **MemoryUtilityEvaluator**: Повышает Utility, если агент помнит, где находится еда.
- **Итог**: Чем сильнее агент хочет есть и чем лучше он знает, где еда, тем выше приоритет этой цели.

### Типы эвалюаторов:
- `StatRangeUtilityEvaluator`: Привязка к характеристикам (голод, усталость, нужда).
- `JobPriorityEvaluator`: Привязка к приоритетам работ, выставленным игроком.
- `TimeOfDayUtilityEvaluator`: Позволяет делать цели более важными ночью (например, сон).

---

## 3. Слой GOAP: Планирование Задач

Используется `GOAPPlanner` с поддержкой обратного связывания и скоринга действий.

### Алгоритм выбора действия (`FindBestAction`):
При выборе действия для удовлетворения прекондишена, планировщик использует формулу скоринга:
`score = count^2 * 50 + action.score * 5 + dependsOnVisited * 100`

- `count`: Сколько требуемых эффектов покрывает действие.
- `action.score`: Базовый приоритет действия (настраивается в `ActionDataSO`).
- `dependsOnVisited`: Бонус за действия, которые зависят от уже запланированных шагов (помогает строить логичные цепочки).

### Паттерн "Transient Target":
Одна из ключевых особенностей — использование "транзитных целей". 
- Действие `MoveTo_Target` дает эффект `Transient_Is/Target`.
- Действие `Interact_Target` требует прекондишен `Transient_Is/Target`.
Это заставляет планировщик всегда ставить "подойти к X" перед "взаимодействовать с X".

---

## 4. Белифы (Beliefs)

Белифы — это атомарные проверки состояния мира или агента. В нашей реализации они представлены классом `AgentBelief` и его ScriptableObject обертками (`BeliefSO`).

### Примеры белифов:
- **Состояние агента**: `HasInInventory/{ITEM}`, `Stat_Hunger_Low`.
- **Память (Memory)**: `Remembers_Nearby/{TAG}` — проверяет пространственную память (Octree) на наличие объектов с нужным тегом.
- **Сенсоры**: `CanSee/{TAG}` — проверка через `VisionSensor`.

Белифы в GOAP работают в обе стороны:
- Как **Preconditions**: Условие, которое должно быть истинно для начала действия.
- Как **Effects**: Состояние, которое станет истинным (или ложным) после завершения действия.

---

## 5. Прерывания и Стек Планов (`AgentBrain`)

Для колонистов (людей) используется расширенный мозг `AgentBrain`, поддерживающий прерывания.

### Interruption System:
`InterruptionManager` проверяет "критические" изменения. Например, если во время рубки дерева у агента критически упал уровень бодрости, срабатывает `CriticalStatInterruption`.

### Plan Stack:
Если текущая задача важна (например, строительство), но возникло прерывание средней важности (голод), мозг:
1. Сохраняет текущую цель и план в `PlanStack`.
2. Переключается на новую цель.
3. После завершения (агент поел), `TryResumePlan` достает старый план из стека и продолжает работу.

---

## 6. Incremental Planner (Оптимизация)

В проекте реализован `IncrementalPlanner`, который пытается переиспользовать или "чинить" старые планы вместо полной пересборки.
- **Cache**: Сохраняет успешные планы для целей.
- **Repair**: Если только 1-2 белифа в плане инвалидировались, планировщик пытается заменить только сломанные звенья цепочки, сохраняя остальную структуру плана.

---

## Примеры из кода

**Типичная цепочка действий (например, сбор ресурса):**
1. **Goal**: `Has_Log_In_Inventory`
2. **Action 1**: `Pickup_Log` (Effect: `Has_Log_In_Inventory`, Pre: `Transient_Is/Log`)
3. **Action 2**: `MoveTo_Log` (Effect: `Transient_Is/Log`, Pre: `Remembers_Nearby/Log`)
4. **Action 3**: `Find_Log` (Effect: `Remembers_Nearby/Log`, Pre: `NONE`)

Если агент уже видит лог, цепочка сокращается до шагов 1 и 2.

---

*Документация подготовлена Джарвисом на основе анализа кода проекта genes.*
